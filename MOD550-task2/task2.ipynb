{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19c82c92",
   "metadata": {},
   "source": [
    "task 2.1: Make a DataModel class that reads the output of the DataAquisition class (from task1) in its __init__()  \n",
    "\n",
    "task 2.2: Make a function in DataModel to make a linear regression. I suggest you try to do it on your own with only vanilla python and the class notes. If you are lost, you can find practical info here on how to use already made libraries: https://www.geeksforgeeks.org/machine-learning/regularization-in-machine-learning/Lenker til en ekstern side.  The issue here will be data structure: np.array vs list of list vs pandas DataFrames.  \n",
    "\n",
    "task 2.3: Make a function that split the data you got from DataAquisition into train, validation and test. Do it  with vanilla python. You need to make sure you understand the data structure.  \n",
    "\n",
    "task 2.4: Make a function that computes MSE (make your own, don't copy from my notes :P )  \n",
    "\n",
    "task 2.5: Make a function to make NN. It would be essentially a wrapper of other libraries, I suggest to use Keras:  https://www.geeksforgeeks.org/machine-learning/how-to-create-models-in-keras/  . You should have acquired enough notions to handle this tool.  \n",
    "\n",
    "task 2.6: Make a function that does K_MEAN and GMM (we will discuss them next week)  \n",
    "\n",
    "Once these methods (recipes) are done, you can now make cakes! :) :  \n",
    "\n",
    "task 2.7: Make a linear regression on all your data (statistic ).  \n",
    "\n",
    "task 2.8: Make a linear regression on all your train data and test it on your validation.  \n",
    "\n",
    "task 2.9: Compute the MSE on your validation data.   \n",
    "\n",
    "task 2.10: Try for different distribution of initial data point, (a) Discuss how different functions can be used in the linear regression, and different NN architecture. (b) Discuss how you can use the validation data for the different cases. (c) Discuss the different outcome from the different models when using the full dataset to train and when you use a different ML approach. (d) Discuss the outcomes you get for K-means and GMM. (e) Discuss how you can integrate supervised and unsupervised methods for your case.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9bfef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../MOD550-task1') # Adjust the path to find data_aquisition module\n",
    "\n",
    "from data_aquisition import DataAquisition as aq\n",
    "import random\n",
    "\n",
    "\n",
    "class DataModel:\n",
    "    def __init__(self):\n",
    "        self.data = aq().data\n",
    "\n",
    "    def linear_regression(self, x, y):\n",
    "        \"\"\"\n",
    "        Performs simple linear regression using the least squares method.\n",
    "        Args:\n",
    "            x (list or array-like): The independent variable values.\n",
    "            y (list or array-like): The dependent variable values.\n",
    "        Returns:\n",
    "            tuple: Intercept (b0) and slope (b1) of the regression line.\n",
    "        \"\"\"\n",
    "        n = len(x)\n",
    "        x_mean = sum(x) / n\n",
    "        y_mean = sum(y) / n\n",
    "        numerator = sum((x[i] - x_mean) * (y[i] - y_mean) for i in range(n))\n",
    "        denominator = sum((x[i] - x_mean) ** 2 for i in range(n))\n",
    "        b1 = numerator / denominator\n",
    "        b0 = y_mean - b1 * x_mean\n",
    "        return b0, b1\n",
    "\n",
    "    def predict(self, x_new, b0, b1):\n",
    "        \"\"\"\n",
    "        Predicts the dependent variable value for a new independent variable input using the linear regression coefficients.\n",
    "        Args:\n",
    "            x_new: The new value of the independent variable.\n",
    "            b0: Intercept of the regression line.\n",
    "            b1: Slope of the regression line.\n",
    "        Returns:\n",
    "            Predicted value of the dependent variable.\n",
    "        \"\"\"\n",
    "        return b0 + b1 * x_new\n",
    "    \n",
    "    def predict_linear_regression(self, x_new, x=None, y=None):\n",
    "        \"\"\"\n",
    "        Predicts the dependent variable value for a new independent variable input using linear regression.\n",
    "        If x and y are not provided, uses the data loaded in self.data, namely 'Release year' as x and 'Rating' as y.\n",
    "        Args:\n",
    "            x_new: The new value of the independent variable to predict for.\n",
    "            x: List or array-like of independent variable values.\n",
    "            y: List or array-like of dependent variable values.\n",
    "        Returns:\n",
    "            Predicted value of the dependent variable for x_new.\n",
    "        \"\"\"\n",
    "        if x is None and y is None:\n",
    "            x = self.data['Release year']\n",
    "            y = self.data['Rating']\n",
    "        elif x is None or y is None:\n",
    "            raise ValueError(\"Both x and y must be provided if one is provided.\")\n",
    "        b0, b1 = self.linear_regression(x, y)\n",
    "        return self.predict(x_new, b0, b1)\n",
    "\n",
    "    def train_val_test_split(self, train_ratio=0.7, val_ratio=0.15, seed=1):\n",
    "        \"\"\"\n",
    "        Splits the dataset into train, validation, and test sets after shuffling.\n",
    "        Args:\n",
    "            train_ratio: Proportion of data to use for training.\n",
    "            val_ratio: Proportion of data to use for validation.\n",
    "            seed (int, optional): Random seed for reproducibility.\n",
    "        Returns:\n",
    "            tuple: (train_data, val_data, test_data) as lists of row dicts.\n",
    "        \"\"\"\n",
    "        if train_ratio + val_ratio > 1:\n",
    "            raise ValueError(\"Ratios are over 1\")\n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "        # Convert column dict to list of row dicts\n",
    "        columns = list(self.data.keys())\n",
    "        n_rows = len(self.data[columns[0]])\n",
    "        rows = [ {col: self.data[col][i] for col in columns} for i in range(n_rows) ]\n",
    "        random.shuffle(rows)\n",
    "        n = len(rows)\n",
    "        n_train = int(n * train_ratio)\n",
    "        n_val = int(n * val_ratio)\n",
    "        train_rows = rows[:n_train]\n",
    "        val_rows = rows[n_train:n_train + n_val]\n",
    "        test_rows = rows[n_train + n_val:]\n",
    "        return train_rows, val_rows, test_rows\n",
    "\n",
    "    def mean_squared_error(self, actual, predicted):\n",
    "        \"\"\"\n",
    "        Computes the Mean Squared Error (MSE) between actual and predicted values.\n",
    "        Args:\n",
    "            actual: True values.\n",
    "            predicted: Predicted values.\n",
    "        Returns:\n",
    "            The mean squared error.\n",
    "        \"\"\"\n",
    "    # Ensure the lists are of the same length\n",
    "        if len(actual) != len(predicted):\n",
    "            raise ValueError(\"Lists must have the same length.\")\n",
    "        n = len(actual)\n",
    "        squared_errors = 0\n",
    "        for i in range(n):\n",
    "            squared_errors += (actual[i] - predicted[i]) ** 2\n",
    "        mse = squared_errors / n\n",
    "        return mse\n",
    "    \n",
    "    def test_MSE(self):\n",
    "        \"\"\"\n",
    "        Fits a linear regression model on the training data and evaluates its performance on the test data using Mean Squared Error (MSE).\n",
    "\n",
    "        Returns:\n",
    "            tuple: (b0, b1, mse)\n",
    "                b0: Intercept of the regression line fitted on the training data.\n",
    "                b1: Slope of the regression line fitted on the training data.\n",
    "                mse: Mean Squared Error of the predictions on the test data.\n",
    "        \"\"\"\n",
    "        data_train, unused , data_test = self.train_val_test_split(train_ratio=0.7, val_ratio=0, seed=1) #To get 30 percent test data)\n",
    "        # Extract x (Release year) and y (Rating) from train data\n",
    "        x_train = [row['Release year'] for row in data_train]\n",
    "        y_train = [row['Rating'] for row in data_train]\n",
    "\n",
    "        # Fit linear regression on train data\n",
    "        b0, b1 = self.linear_regression(x_train, y_train)\n",
    "        x_test = [row['Release year'] for row in data_test]\n",
    "        y_test = [row['Rating'] for row in data_test]\n",
    "\n",
    "        # Predict on test data\n",
    "        y_pred = [self.predict(x, b0, b1) for x in x_test]\n",
    "\n",
    "        # Calculate MSE\n",
    "        mse = self.mean_squared_error(y_test, y_pred)\n",
    "        return b0, b1, mse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd29a909",
   "metadata": {},
   "source": [
    "**Part 1**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff0a4fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File found: ../title.basics.tsv\n",
      "File found: ../data/title.ratings.tsv\n"
     ]
    }
   ],
   "source": [
    "dataw = DataModel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944366a7",
   "metadata": {},
   "source": [
    "**Part 2**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dd490c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(7.0657166085933705)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataw.predict_linear_regression(x_new=2040)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c747f000",
   "metadata": {},
   "source": [
    "**Part 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45f4f005",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_validation, data_test = dataw.train_val_test_split(seed=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c543eceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training set: 191088\n",
      "Length of validation set: 40947\n",
      "Length of test set: 40949\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of training set:\", len(data_train))\n",
    "print(\"Length of validation set:\", len(data_validation))\n",
    "print(\"Length of test set:\", len(data_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a86e1c9",
   "metadata": {},
   "source": [
    "**Part 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7612c1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept (b0): -6.3419693651290885 Slope (b1): 0.006570642790351797 MSE: 1.834137841834273\n"
     ]
    }
   ],
   "source": [
    "model_b0, model_b1, model_mse = dataw.test_MSE()\n",
    "print(\"Intercept (b0):\", model_b0, \"Slope (b1):\", model_b1, \"MSE:\", model_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42737762",
   "metadata": {},
   "source": [
    "**Part 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54500401",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-08 07:38:59.687220: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-10-08 07:39:00.581056: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-08 07:39:04.021073: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8073451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_nn(input_dim, layers_units=[64, 32], activation='relu', output_activation='linear', optimizer='adam', loss='mse'):\n",
    "    \"\"\"\n",
    "    Creates and compiles a simple feedforward neural network using Keras.\n",
    "    \n",
    "    Args:\n",
    "        input_dim (int): Number of input features.\n",
    "        layers_units (list): List with the number of units in each hidden layer.\n",
    "        activation (str): Activation function for hidden layers.\n",
    "        output_activation (str): Activation function for output layer.\n",
    "        optimizer (str): Optimizer to use.\n",
    "        loss (str): Loss function to use.\n",
    "        \n",
    "    Returns:\n",
    "        keras.Model: Compiled Keras model.\n",
    "    \"\"\"\n",
    "    model = keras.Sequential()\n",
    "    # Input layer\n",
    "    model.add(layers.Input(shape=(input_dim,)))\n",
    "    # Hidden layers\n",
    "    for units in layers_units:\n",
    "        model.add(layers.Dense(units, activation=activation))\n",
    "    # Output layer\n",
    "    model.add(layers.Dense(1, activation=output_activation))\n",
    "    model.compile(optimizer=optimizer, loss=loss)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "008bead1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best architecture: [64, 32] Validation MSE: 1.8335663080215454\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# We'll use the make_nn function to try different architectures and find the one with the lowest validation MSE.\n",
    "# We'll try a few combinations of hidden layers and units.\n",
    "\n",
    "def evaluate_nn_architectures(x_train, y_train, x_val, y_val, architectures, epochs=5, batch_size=128):\n",
    "    results = []\n",
    "    for arch in architectures:\n",
    "        model = make_nn(input_dim=x_train.shape[1], layers_units=arch)\n",
    "        history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0, validation_data=(x_val, y_val))\n",
    "        val_mse = history.history['val_loss'][-1]\n",
    "        results.append({'architecture': arch, 'val_mse': val_mse})\n",
    "    return sorted(results, key=lambda x: x['val_mse'])\n",
    "\n",
    "# Prepare data: extract features and target from data_train and data_validation\n",
    "\n",
    "def extract_xy(data):\n",
    "    # Use 'Release year' as feature, 'Rating' as target\n",
    "    x = np.array([[row['Release year']] for row in data])\n",
    "    y = np.array([row['Rating'] for row in data])\n",
    "    return x, y\n",
    "\n",
    "x_train, y_train_nn = extract_xy(data_train)\n",
    "x_val, y_val_nn = extract_xy(data_validation)\n",
    "\n",
    "# Try different architectures\n",
    "architectures = [\n",
    "    [32],\n",
    "    [64],\n",
    "    [128],\n",
    "    [64, 32],\n",
    "    [128, 64],\n",
    "    [128, 64, 32]\n",
    "]\n",
    "\n",
    "results = evaluate_nn_architectures(x_train, y_train_nn, x_val, y_val_nn, architectures, epochs=3, batch_size=256)\n",
    "best = results[0]\n",
    "print(\"Best architecture:\", best['architecture'], \"Validation MSE:\", best['val_mse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880a47bf",
   "metadata": {},
   "source": [
    "**Part 7**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f113334d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

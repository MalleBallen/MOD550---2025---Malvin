{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19c82c92",
   "metadata": {},
   "source": [
    "task 2.1: Make a DataModel class that reads the output of the DataAquisition class (from task1) in its __init__()  \n",
    "\n",
    "task 2.2: Make a function in DataModel to make a linear regression. I suggest you try to do it on your own with only vanilla python and the class notes. If you are lost, you can find practical info here on how to use already made libraries: https://www.geeksforgeeks.org/machine-learning/regularization-in-machine-learning/Lenker til en ekstern side.  The issue here will be data structure: np.array vs list of list vs pandas DataFrames.  \n",
    "\n",
    "task 2.3: Make a function that split the data you got from DataAquisition into train, validation and test. Do it  with vanilla python. You need to make sure you understand the data structure.  \n",
    "\n",
    "task 2.4: Make a function that computes MSE (make your own, don't copy from my notes :P )  \n",
    "\n",
    "task 2.5: Make a function to make NN. It would be essentially a wrapper of other libraries, I suggest to use Keras:  https://www.geeksforgeeks.org/machine-learning/how-to-create-models-in-keras/  . You should have acquired enough notions to handle this tool.  \n",
    "\n",
    "task 2.6: Make a function that does K_MEAN and GMM (we will discuss them next week)  \n",
    "\n",
    "Once these methods (recipes) are done, you can now make cakes! :) :  \n",
    "\n",
    "task 2.7: Make a linear regression on all your data (statistic ).  \n",
    "\n",
    "task 2.8: Make a linear regression on all your train data and test it on your validation.  \n",
    "\n",
    "task 2.9: Compute the MSE on your validation data.   \n",
    "\n",
    "task 2.10: Try for different distribution of initial data point, (a) Discuss how different functions can be used in the linear regression, and different NN architecture. (b) Discuss how you can use the validation data for the different cases. (c) Discuss the different outcome from the different models when using the full dataset to train and when you use a different ML approach. (d) Discuss the outcomes you get for K-means and GMM. (e) Discuss how you can integrate supervised and unsupervised methods for your case.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0a4fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File found: ../title.basics.tsv\n",
      "File found: ../data/title.ratings.tsv\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../MOD550-task1')  # replace with the actual folder path\n",
    "\n",
    "from data_aquisition import DataAquisition as aq\n",
    "aqinstance = aq()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc3151b",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_df['startYear'] = pd.to_numeric(compiled_df['startYear'], errors='coerce') # Convert to numeric, setting errors to NaN\n",
    "\n",
    "compiled_df = compiled_df.rename(columns={\n",
    "    'tconst': 'Title ID',\n",
    "    'startYear': 'Release year',\n",
    "    'averageRating': 'Rating',\n",
    "    'numVotes': 'Number of votes'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2b81424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../title.basics.tsv\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Assuming aqinstance has a method or attribute to access the data, e.g., aqinstance.data or aqinstance.get_data()\n",
    "# Let's read 'tconst' and one other column, e.g., 'title'\n",
    "print(aqinstance.basics_path_)\n",
    "data = aqinstance.read_file_tsv(aqinstance.basics_path_, columns=['tconst', 'startYear'], nrows=None)\n",
    "data2= aqinstance.read_file_tsv(aqinstance.basics_path_, columns=['tconst', 'primaryTitle'], nrows=None)\n",
    "data3 = aqinstance.read_file_tsv(aqinstance.basics_path_, columns=['tconst', 'genres'], nrows=None)\n",
    "\n",
    "data5 = aqinstance.read_file_tsv(aqinstance.ratings_path_, columns=['tconst', 'averageRating', 'numVotes'], nrows=None)\n",
    "print(data3.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
